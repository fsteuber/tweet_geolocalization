{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import json\n",
    "from os import listdir\n",
    "from os.path import join, isfile\n",
    "from scipy.sparse import load_npz\n",
    "from scipy import sparse\n",
    "from sklearn.ensemble import AdaBoostClassifier, StackingClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "\n",
    "from sklearn.metrics import normalized_mutual_info_score, cohen_kappa_score\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Training und Anwendung des Klassifikators</h1>\n",
    "\n",
    "In diesem Notebook implementieren wir eine etwas kompaktere Variante des hierarchischen Klassifikators. Dieser besitzt nur zwei Ebenen, so dass die Zahl der zu trainierenden Modelle für den Workshop übersichtlich gehalten wird. Der Aufbau des Notebook Files ist wie folgt:\n",
    "\n",
    "1. Extraktion der Hierarchieebenen und Zuordnung von Polygon-IDs\n",
    "2. Einlesen der bisherigen Feature-Files\n",
    "3. Codierung von verbleibenden Merkmalen\n",
    "4. Implementierung des Stacked Classifiers für Kontextmerkmale\n",
    "5. Implementierung des Ensemblings für Kontext- und Kontentergebnisse\n",
    "6. Implementierung des Abstainings\n",
    "\n",
    "<h2>1. Extraktion der Hierarchieebenen und Zuordnung von Polygon-IDs</h2>\n",
    "\n",
    "Im Skript *1-CreateLabels.ipynb* hatten wir durch das agglomerative Clustering ein Dendrogramm von Polygon-IDs berechnet. Dieses ist im File *place_hierarchy.pcl* serialisiert. Der erste Schritt wird es nun sein, diese Datenstruktur zu durchlaufen und die Zwischenebene für die schrittweise Klassifikation zu identifizieren. Die erste Ebene klassifiziert hier, wie bekannt, in eine von vier Teilbereichen der Welt, etwa auf der räumlichen Präzision von Kontinenten. Die zweite Ebene würde von dieser Kontinentalebene nun abweichend direkt auf die 150 Zielklassen abbilden.\n",
    "\n",
    "Zur Berechnung der vier Cluster, welche für den ersten Klassifikationsschritt relevant sind, definieren wir unten eine Hilfsfunktion *get_N_splits(tree, N)*. Diese erwartet eine Baumstruktur, welche dem Dendrogramm entspricht, über die iteriert werden kann, vgl. *tree*. Des Weiteren muss eine Zahl *N* von gewünschten Clustern übergeben werden. Der Output der Methode ist dann eine Liste, welche *N* weitere Listen enthält. Jede dieser *N* inneren Listen repräsentiert einen der gewünschten Cluster und beinhaltet für sich wiederum alle Polygon-IDs, welche diesem Cluster zugeordnet sind. Wir sehen unten gleich in der Praxis, wie die Datenstrukturen genau aussehen.\n",
    "\n",
    "Die *N* Cluster erhält man aus dem Dendrogramm normalerweise, indem der Baum, von der Wurzel ausgehend, an seinen obersten *N* Abzweigungen zertrennt wird. Das Resultat sind dann *N* Teilbäume, welche die Polygon-IDs des entsprechenden Teilclusters in den Blättern halten. Anders als bei der soeben beschriebenen exakten Unterteilung implementieren wir für den Workshop eine etwas andere (leichtere) Variante, die Teilbäume zu berechnen. Konkret gehen wir davon aus, dass die Abzweigungen zumindest nahe der Wurzel ungefähr gleichmäßig auf beide Seiten des Baumes verteilt sind. In diesem Fall kann eine einfache Verarbeitungsvorschrift für Binärbäume angegeben werden, welche abhängig von der gewünschten Tiefe des Baumes (oder äquivalent gewünschten Zahl an Teilbäumen) die Split-Knoten bestimmt.\n",
    "\n",
    "So wäre beispielsweise beim Split in $2$ Teilbäume (ausgehend von der Wurzel) einmal der **l**inke und einmal der **r**echte Teilbaum als eigenständiger Cluster zu betrachten. Soll ein Binärbaum gleichmäßig in $4$ Teile aufgeteilt werden, so könnten die Wurzeln der vier Teilbäume erreicht werden, indem folgendermaßen durch den Baum navigiert wird: a) links, links (kurz **ll**), b) links, rechts (kurz **lr**), c) rechts, links (kurz **rl**), sowie d) rechts, rechts (kurz **rr**). Ähnliches gilt für weitere Unterteilungen mit mehr Teilbäumen.\n",
    "\n",
    "Damit die Funktion *get_N_splits()* nun die *N* Teilbäume extrahieren kann, wird im Code wie folgt vorgegangen. Wie bereits beschrieben, gehen wir vereinfachend davon aus, dass das Dendrogramm ein Binärbaum ist. Auf welcher Ebene der Baum zertrennt werden muss, um *N* Teilbäume auf gleicher Ebene zu erhalten, berechnen wir den Zweierlogarithmus von *N*. So bedeutet *required_depth* $= log_2(4) = 2$ etwa, dass wir zwei mal von der Wurzel ausgehend (auf insgesamt vier verschiedene Arten) durch den Baum navigieren müssen, um auf die vier unterschiedlichen Teilbäume zu kommen. Die Hilfsmethode *get_subtree_position(depth)* berechnet die Potenzmenge aller Navigationsmöglichkeiten auf dieser Tiefe des Baumes, für *N*$=4$ also bspw. [**ll**, **lr**, **rl**, **rr**].\n",
    "\n",
    "Für jede dieser Durchlaufvorschriften, im Code unten als *subtrees* bezeichnet, durchlaufen wir nun das übergebene Dendrogramm *root* (von der Wurzel) aus, indem wir, je nach Character der Durchlaufvorschrift, auf den jeweils linken oder rechten Nachfolger referenzieren (vgl. *current_position.get_left()* oder *current_position.get_right()*. Sind wir dann bei der Wurzel des Teilbaumes angelangt, können alle in diesem Teilbaum verbleibenden Knoten dem Selben Cluster zugeordnet werden. Einer dieser *subtree_clusters* kann bspw. erhalten werden, indem auf dem aktuellen Teilbaum ein Preorder Baumdurchlauf durchgeführt wird: *current_position.pre_order()*.\n",
    "\n",
    "Nach der Abarbeitung eines Teilbaumes kehren wir zur Wurzel zurück und extrahieren auf gleiche Weise den nächsten Teilbaum. Sind alle Teilbäume abgearbeitet, gibt die Funktion die Liste von Clustern zurück."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subtree_position(depth):\n",
    "    res = [\"l\", \"r\"]\n",
    "    if depth > 1:\n",
    "        children = get_subtree_position(depth - 1)\n",
    "        res = [element + child for child in children for element in res]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_N_splits(root, N, balanced=True):\n",
    "    \n",
    "    if balanced:\n",
    "        subtree_clusters = []\n",
    "\n",
    "        # note that the hierarchical tree is not balanced, hence a too large N will result in an error eventually\n",
    "        required_depth = np.log2(N)\n",
    "        subtrees = get_subtree_position(required_depth)\n",
    "\n",
    "        for subtree in subtrees:\n",
    "            current_position = root  # start at root\n",
    "            for char in subtree:  # navigate through the tree to find root of subtree\n",
    "                if char == \"l\":\n",
    "                    current_position = current_position.get_left()\n",
    "                else:\n",
    "                    current_position = current_position.get_right()\n",
    "            subtree_clusters.append(current_position.pre_order())  # get all leaf nodes of current subtree\n",
    "            \n",
    "        return subtree_clusters\n",
    "    else:  # not balanced\n",
    "        subtrees = [root]\n",
    "        \n",
    "        while len(subtrees) < N:\n",
    "            max_pos = -1\n",
    "            max_len = -1\n",
    "            \n",
    "            # find largest subtree\n",
    "            for i, subtree in enumerate(subtrees):\n",
    "                l = len(subtree.pre_order())\n",
    "                if l > max_len:\n",
    "                    max_len = l\n",
    "                    max_pos = i\n",
    "                    \n",
    "            # keep all smaller subtrees\n",
    "            new_subtrees = [s for i, s in enumerate(subtrees) if i != max_pos]\n",
    "            # and split the largest one\n",
    "            new_subtrees.append(subtrees[max_pos].get_left())\n",
    "            new_subtrees.append(subtrees[max_pos].get_right())\n",
    "            subtrees = new_subtrees\n",
    "            \n",
    "        subtrees = [s.pre_order() for s in subtrees]\n",
    "        return subtrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der nächsten Zeile werden die soeben definierten Hilfsfunktionen in der Praxis aufgerufen. Hierzu wird zunächst das serialisierte Dendrogramm aus dem File *place_hierarchy.pcl* geladen. Für den Workshop würde es nun ausreichen, die eine zusätzliche Hierarchieebene mit vier Clustern durch den Funktionsaufruf *get_N_splits(ch, 4)* zu extrahieren.\n",
    "\n",
    "Für komplexere Szenarien mit mehr Ebenen muss der entsprechende Funktionsaufruf häufiger durchgeführt werden, nämlich einmal pro gewünschter Zahl an Cluster. Im Code unten ist dies bereits automatisiert geregelt. Hierzu wird ein Dictionary $C$ von Clustern erzeugt. Jedes Key-Value-Paar des Dictionarys hält dann die Informationen darüber, wie der Baum in eine feste, jedoch immer unterschiedliche Zahl von Clustern unterteilt wird. So würde beispielsweise der Aufruf *C[4]* eine Liste von $4$ Clustern mit Polygon-IDs zurück liefern, *C[16]* eine Liste von $16$ Clustern mit Polygon-IDs (das wäre im Projekt die zweite Ebene) usw...\n",
    "\n",
    "Aus diesen Clusterergebnissen können nun die **Labels von Datenpunkten für die Zwischenebenen** berechnet werden. Auf Kontinentalebene, d.h. für vier Zielklassen, erwartet der Algorithmus nämlich natürlich nicht die 150 Polygon-IDs, sondern eine von vier Cluster-IDs. Glücklicherweise ist die Gruppierung bereits in der *C[4]* Liste enthalten, da dort ja die vier Listen von Polygon-IDs existieren. Wir stellen diese Datenstruktur nun noch so um, dass wir direkt von Polygon-ID auf Cluster-ID abbilden können, indem das entsprechende *C[4]* Dictionary transponiert wird. \n",
    "\n",
    "Das Ergebnis ist ein neues Dictionary *C4_T* (grob für \"vier Cluster & transponiert\"), welches als Keys die Polygon-IDs und als Values die entsprechende Cluster-ID besitzt. Wollen wir für das Training des Klassifikators erster Ebene nun also beispielsweise einen Datenpunkt des Polygons $55$ nutzen, so hätte dieses Polygon auf der dieser Ebene das Label *C4_T[55]*. \n",
    "\n",
    "Bei komplexeren Klassifikatoren mit mehr Ebenen (wie beispielsweise direkt im Projekt) müsste zusätzlich noch ein Mapping von $C4$-IDs auf $C16$-IDs vorgenommen werden. Der entsprechende Code ist unten in Kommentaren mit beigefügt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nC16_T = {}\\nfor cluster_id, members in enumerate(C[16]):\\n    for member in members:\\n        C16_T[member] = cluster_id\\n        \\nC4_to_C16 = defaultdict(set)\\n# 4 -> 16 Mapping\\nfor cluster_id, members in enumerate(C[4]):\\n    for member in members:\\n        C4_to_C16[cluster_id].add(C16_T[member])\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load hierarchy\n",
    "ch = pickle.load(open(\"place_hierarchy.pcl\", \"rb\"))\n",
    "\n",
    "# Cluster Dictionary\n",
    "C = {2**i: get_N_splits(ch, 2**i) for i in range(1,4)}\n",
    "C4_T = {}\n",
    "for cluster_id, members in enumerate(C[4]):\n",
    "    for member in members:\n",
    "        C4_T[member] = cluster_id\n",
    "\n",
    "\"\"\"\n",
    "C16_T = {}\n",
    "for cluster_id, members in enumerate(C[16]):\n",
    "    for member in members:\n",
    "        C16_T[member] = cluster_id\n",
    "        \n",
    "C4_to_C16 = defaultdict(set)\n",
    "# 4 -> 16 Mapping\n",
    "for cluster_id, members in enumerate(C[4]):\n",
    "    for member in members:\n",
    "        C4_to_C16[cluster_id].add(C16_T[member])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier noch die versprochenen Beispiele, wie die Datenstrukturen jeweils aussehen. Wir beginnen mit der Naviagtionsvorschrift des Graphdurchlaufs, so dass insgesamt $8$ Teilbäume entstehen. Somit müssen $log_2(8)=3$ Navigationsschritte von der Wurzel aus durchgeführt werden. Diese sind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lll', 'rll', 'lrl', 'rrl', 'llr', 'rlr', 'lrr', 'rrr']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_subtree_position(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durchläuft man das Dendrogramm, so ergeben sich folgende Cluster mit entsprechenden Poylgon-IDs. Hier wird schnell ersichtlich, dass der Baum nicht ausbalanciert ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: [97]\n",
      "Cluster 1: [83, 137, 116, 76, 38, 125, 34, 99, 90, 17, 85, 72, 134, 135, 87, 4, 64, 67, 28, 136, 19, 111, 1, 143, 88, 148, 31, 53, 12, 68, 41, 117, 50, 124]\n",
      "Cluster 2: [80, 49, 100, 5, 57, 141, 45, 114]\n",
      "Cluster 3: [54, 144, 32, 65, 43, 15, 37, 109, 71, 59, 123, 70, 2, 103, 14, 128, 75, 18, 127, 8, 95, 30, 139, 42, 129, 36, 107]\n",
      "Cluster 4: [26, 52, 138]\n",
      "Cluster 5: [130, 73, 33, 48, 23, 69, 110, 16, 77, 56, 145, 79, 7, 122]\n",
      "Cluster 6: [11, 92, 101, 147, 21, 74, 22, 51, 62, 94, 44, 86, 78, 140, 60, 119, 10, 47, 126, 106, 29, 149, 0, 105, 115, 133, 27, 58, 120, 131, 96, 40, 91, 3, 35, 132, 102, 25, 142, 55, 24, 82, 61, 113, 46, 108, 98, 13, 66]\n",
      "Cluster 7: [9, 112, 81, 89, 20, 146, 63, 93, 6, 104, 84, 121, 39, 118]\n"
     ]
    }
   ],
   "source": [
    "clusters = get_N_splits(ch, 8)\n",
    "for i, c in enumerate(clusters):\n",
    "    print(\"Cluster {}: {}\".format(i, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die transponierte Darstellung zu obigem Beispiel wäre:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{97: 0,\n",
       " 83: 1,\n",
       " 137: 1,\n",
       " 116: 1,\n",
       " 76: 1,\n",
       " 38: 1,\n",
       " 125: 1,\n",
       " 34: 1,\n",
       " 99: 1,\n",
       " 90: 1,\n",
       " 17: 1,\n",
       " 85: 1,\n",
       " 72: 1,\n",
       " 134: 1,\n",
       " 135: 1,\n",
       " 87: 1,\n",
       " 4: 1,\n",
       " 64: 1,\n",
       " 67: 1,\n",
       " 28: 1,\n",
       " 136: 1,\n",
       " 19: 1,\n",
       " 111: 1,\n",
       " 1: 1,\n",
       " 143: 1,\n",
       " 88: 1,\n",
       " 148: 1,\n",
       " 31: 1,\n",
       " 53: 1,\n",
       " 12: 1,\n",
       " 68: 1,\n",
       " 41: 1,\n",
       " 117: 1,\n",
       " 50: 1,\n",
       " 124: 1,\n",
       " 80: 2,\n",
       " 49: 2,\n",
       " 100: 2,\n",
       " 5: 2,\n",
       " 57: 2,\n",
       " 141: 2,\n",
       " 45: 2,\n",
       " 114: 2,\n",
       " 54: 3,\n",
       " 144: 3,\n",
       " 32: 3,\n",
       " 65: 3,\n",
       " 43: 3,\n",
       " 15: 3,\n",
       " 37: 3,\n",
       " 109: 3,\n",
       " 71: 3,\n",
       " 59: 3,\n",
       " 123: 3,\n",
       " 70: 3,\n",
       " 2: 3,\n",
       " 103: 3,\n",
       " 14: 3,\n",
       " 128: 3,\n",
       " 75: 3,\n",
       " 18: 3,\n",
       " 127: 3,\n",
       " 8: 3,\n",
       " 95: 3,\n",
       " 30: 3,\n",
       " 139: 3,\n",
       " 42: 3,\n",
       " 129: 3,\n",
       " 36: 3,\n",
       " 107: 3,\n",
       " 26: 4,\n",
       " 52: 4,\n",
       " 138: 4,\n",
       " 130: 5,\n",
       " 73: 5,\n",
       " 33: 5,\n",
       " 48: 5,\n",
       " 23: 5,\n",
       " 69: 5,\n",
       " 110: 5,\n",
       " 16: 5,\n",
       " 77: 5,\n",
       " 56: 5,\n",
       " 145: 5,\n",
       " 79: 5,\n",
       " 7: 5,\n",
       " 122: 5,\n",
       " 11: 6,\n",
       " 92: 6,\n",
       " 101: 6,\n",
       " 147: 6,\n",
       " 21: 6,\n",
       " 74: 6,\n",
       " 22: 6,\n",
       " 51: 6,\n",
       " 62: 6,\n",
       " 94: 6,\n",
       " 44: 6,\n",
       " 86: 6,\n",
       " 78: 6,\n",
       " 140: 6,\n",
       " 60: 6,\n",
       " 119: 6,\n",
       " 10: 6,\n",
       " 47: 6,\n",
       " 126: 6,\n",
       " 106: 6,\n",
       " 29: 6,\n",
       " 149: 6,\n",
       " 0: 6,\n",
       " 105: 6,\n",
       " 115: 6,\n",
       " 133: 6,\n",
       " 27: 6,\n",
       " 58: 6,\n",
       " 120: 6,\n",
       " 131: 6,\n",
       " 96: 6,\n",
       " 40: 6,\n",
       " 91: 6,\n",
       " 3: 6,\n",
       " 35: 6,\n",
       " 132: 6,\n",
       " 102: 6,\n",
       " 25: 6,\n",
       " 142: 6,\n",
       " 55: 6,\n",
       " 24: 6,\n",
       " 82: 6,\n",
       " 61: 6,\n",
       " 113: 6,\n",
       " 46: 6,\n",
       " 108: 6,\n",
       " 98: 6,\n",
       " 13: 6,\n",
       " 66: 6,\n",
       " 9: 7,\n",
       " 112: 7,\n",
       " 81: 7,\n",
       " 89: 7,\n",
       " 20: 7,\n",
       " 146: 7,\n",
       " 63: 7,\n",
       " 93: 7,\n",
       " 6: 7,\n",
       " 104: 7,\n",
       " 84: 7,\n",
       " 121: 7,\n",
       " 39: 7,\n",
       " 118: 7}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C8_T = {}\n",
    "for cluster_id, members in enumerate(C[8]):\n",
    "    for member in members:\n",
    "        C8_T[member] = cluster_id\n",
    "C8_T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2. Einlesen der bisherigen Feature Files</h2>\n",
    "\n",
    "Zu diesem Zeitpunkt haben wir (fast) genügend Informationen gesammelt und aufbereitet, um mit dem Training der Klassifikatoren beginnen zu können. Daher ist es an der Zeit, die Vorverarbeiteten Tweets in den Arbeitsspeicher zu laden. Zur Erinnerung: wir verarbeiten Kontext- und Textmerkmale aus Tweets individuell. Die Textmerkmale wurden mit den Anweisungen des zweiten Skriptes *2-ExtractFeatures.ipynb* bereits klassifiziert und stehen als Wahrscheinlichkeitsverteilung über die $150$ Zielklassen in Form einer CSR-Matrix zur Verfügung. \n",
    "\n",
    "Die Kontextkomponenten sind noch nicht klassifiziert, da der zugehörige gestapelte Klassifikator in diesem Skript zunächst noch erstellt werden muss. Die Merkmale sind zudem in zwei unterschiedlichen Files abgelegt, nämlich einerseits einer **.features* CSV-Datei (in der kategorische Merkmale noch nicht in eine numerische Form übersetzt wurden) und andererseits einer **.loc* Datei, welche die Polygon-ID-Vorhersagen für die Profil-Locations der Nutzer hält.\n",
    "\n",
    "In der Praxis existieren von all diesen Dateien mehrere Exemplare, da die initialen Tweet-Files auch in mehreren Files abgespeichert waren. Somit müssen in dieser Zelle a) zusammengehörige **.feature*, **.loc* und **.pred.npz* Dateien kombiniert werden und b) alle Paare von Dateien eingelesen werden, so dass der Datensatz vollständig in den Speicher geladen wird.\n",
    "\n",
    "Hinsichtlich der Problematik a) muss nur überprüft werden, ob das File-Prefix der individuellen Dateien übereinstimmt. Die Problematik aus b) lässt sich über das Framework *pandas* auch sehr einfach lösen, da Teilmatrizen mit identischen Dimensionen einfach zu einer großen Matrix konkateniert werden können, siehe nächste Zelle.\n",
    "\n",
    "Für die Ergebnisse der Textklassifikation werden noch zwei zusätzliche Verarbeitungsschritte getätigt, damit die Klassifikation später fortlaufend durchgeführt werden kann. Neben den gegebenen Wahrscheinlichkeitsverteilungen über die Zielklassen wird noch das wahrscheinlichste Label (in der Spalte $150$) angegeben. Zudem werden vier neue Spalten *4\\_0*, ... *4\\_3* erstellt, welche die Wahrscheinlichkeitswerte beinhalten, dass ein Datenpunkt aus dem Cluster $0$, ...$3$ der Ebene 1 (d.h. bei der Klassifikation in $4$ Klassen) entstammt. Diese Wahrscheinlichkeit berechnet sich entsprechend aus der Summe der Teilwahrscheinlichkeiten aller der aus diesem Cluster stammenden Polygon-IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 20.06it/s]\n"
     ]
    }
   ],
   "source": [
    "path = \"data/feature_files/\"\n",
    "files = [path + f for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "# Files vorbereiten\n",
    "feature_files = [f for f in files if f[-8:] == \"features\"]\n",
    "geocoding_files = [f for f in files if f[-3:] == \"loc\"]\n",
    "text_files = [f for f in files if f[-8:] == \"pred.npz\"]\n",
    "\n",
    "# Variablen definieren\n",
    "tmp_feat = []\n",
    "tmp_text = []\n",
    "tmp_labels = []\n",
    "\n",
    "for feature_file in tqdm(sorted(feature_files, reverse=True)):  # füŕ jedes File\n",
    "    \n",
    "    # Variablen zurücksetzen\n",
    "    df_feat = None\n",
    "    df_text = None\n",
    "    df_labels = None\n",
    "        \n",
    "    file_prefix = feature_file.split(\".\")[0]\n",
    "        \n",
    "    # Filenamen filtern\n",
    "    geo_file = [f for f in geocoding_files if file_prefix in f][0]\n",
    "    text_file = [f for f in text_files if file_prefix in f][0]\n",
    "\n",
    "    \"\"\"\n",
    "    Data Frames erstellen\n",
    "    \"\"\"\n",
    "    # 1. Feature Data Frame\n",
    "    df_feat = pd.read_csv(feature_file, delimiter=\";\")\n",
    "        \n",
    "    # Profile Location ist noch in einem anderen File abgespeichert, weil die vorherige Pipeline \n",
    "    # die Daten noch durch den Geocoder prozessieren lassen musste... hier findet der Merge statt\n",
    "    df_geo = pd.read_csv(geo_file)\n",
    "    df_feat[\"profile_location\"] = df_geo[\"profile_location\"]\n",
    "    del df_geo\n",
    "    tmp_feat.append(df_feat)\n",
    "    \n",
    "    # 2. Text Data Frame\n",
    "    df_text = pd.DataFrame(sparse.load_npz(text_file).todense())\n",
    "    df_text = df_text.iloc[1: , :]\n",
    "    \n",
    "    tmp_text.append(df_text)\n",
    "    \n",
    "    # 3. Label Data Frame\n",
    "    df_labels = pd.DataFrame()\n",
    "    df_labels[\"150\"] = df_feat[\"label\"]\n",
    "    df_feat = df_feat.drop(columns=\"label\")\n",
    "    \n",
    "    # Hierarchieebenen definieren\n",
    "    df_labels[\"4\"] = df_labels[\"150\"].apply(lambda n: C4_T[n])\n",
    "    \n",
    "    \"\"\"\n",
    "    Text Wahrscheinlichkeiten für Layer 1 aufbereiten \n",
    "    (Top 10 Klassen mit W'keiten von Layer 2 sind gegeben)\n",
    "    \"\"\"\n",
    "    # Zu Beginn sind die Labels 0..149 mit W'keiten gefüllt, falls sie in den Top 10 sind, sonst mit 0\n",
    "    # Label 150 ist die Gegenw'keit, d.h. 1- Summe(Top10)\n",
    "    \n",
    "    # Diskretisiere Text-Label für Layer 2 via Argmax:\n",
    "    df_text[\"150\"] = df_text.idxmax(axis=1)  # get argmax cluster id for each data point\n",
    "    \n",
    "    # Falls Gegenw'keit > .5, d.h. Vorhersage unsicher war, dann deklariere Datenpunkt als -1, also\n",
    "    # als \"unschlüsslig\"\n",
    "    df_text[\"150\"] = df_text[\"150\"].apply(lambda n: n if n != 150 else -1)  # Top Predictions < .5\n",
    "\n",
    "    # sum the probabilities of subclusters that belong into the same cluster\n",
    "    for i, member in enumerate(C[4]):\n",
    "        df_text[\"4_{}\".format(i)] = 0\n",
    "        for m in member:\n",
    "            df_text[\"4_{}\".format(i)] += df_text[m]\n",
    "    \n",
    "    tmp_labels.append(df_labels)\n",
    "\n",
    "\n",
    "    \n",
    "df_feat = pd.concat(tmp_feat, axis=0, ignore_index=True)\n",
    "df_text = pd.concat(tmp_text, axis=0, ignore_index=True)\n",
    "df_labels = pd.concat(tmp_labels, axis=0, ignore_index=True)\n",
    "\n",
    "del tmp_feat\n",
    "del tmp_text\n",
    "del tmp_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Betrachten wir die nun die Ergebnisse der Extraktion. \n",
    "\n",
    "Das *df_labels* Dataframe enthält die Labels aller grob $46000$ Datenpunkte. Die Spalte $150$ bezieht sich dabei auf die Polygon-ID, d.h. das korrekte Label bei $150$ Möglichkeiten. Die Spalte $4$ beinhaltet das Label des Clusters, wenn der Datenpunkt auf der ersten Hierarchieebene in einen von eben $4$ Clustern vorhergesagt werden muss.\n",
    "\n",
    "Das *df_text* Dataframe enthält, wie bereits bekannt, die Wahrscheinlichkeitsverteilungen über die 150 Zielklassen, sowie die Gegenwahrscheinlichkeit aka Noise. Zusätzlich ist das wahrscheinlichste Label, sowie die Wahrscheinlichkeitsverteilung für Cluster der ersten Ebene in vier Zielklassen gegeben.\n",
    "\n",
    "Das *df_feat* Dataframe enthält nun alle Kontextmerkmale, d.h. auch die Profil-Location des Nutzers. Jedoch müssen hier noch Daten aus den kategorischen Spalten, wie *language* oder *source* konvertiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>150</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>147</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46430</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46431</th>\n",
       "      <td>115</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46432</th>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46433</th>\n",
       "      <td>132</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46434</th>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46435 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       150  4\n",
       "0       94  2\n",
       "1       40  2\n",
       "2      106  2\n",
       "3       29  2\n",
       "4      147  2\n",
       "...    ... ..\n",
       "46430   35  2\n",
       "46431  115  2\n",
       "46432   49  2\n",
       "46433  132  2\n",
       "46434  116  1\n",
       "\n",
       "[46435 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>150</th>\n",
       "      <th>4_0</th>\n",
       "      <th>4_1</th>\n",
       "      <th>4_2</th>\n",
       "      <th>4_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072442</td>\n",
       "      <td>83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.927558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009680</td>\n",
       "      <td>55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138538</td>\n",
       "      <td>0.851782</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.304313</td>\n",
       "      <td>83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.562199</td>\n",
       "      <td>0.133488</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048659</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.218158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.733183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.179389</td>\n",
       "      <td>83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.820611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46430</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.147621</td>\n",
       "      <td>0.842379</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46431</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.186476</td>\n",
       "      <td>83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.758250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46432</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109235</td>\n",
       "      <td>83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.890765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46433</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.931571</td>\n",
       "      <td>0.067151</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46434</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139281</td>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.860719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46435 rows × 156 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2    3    4    5    6    7    8    9  ...  146  147  148  \\\n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "46430  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "46431  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "46432  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "46433  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "46434  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "       149       150  150  4_0       4_1       4_2       4_3  \n",
       "0      0.0  0.072442   83  0.0  0.927558  0.000000  0.000000  \n",
       "1      0.0  0.009680   55  0.0  0.138538  0.851782  0.000000  \n",
       "2      0.0  0.304313   83  0.0  0.562199  0.133488  0.000000  \n",
       "3      0.0  0.048659   30  0.0  0.218158  0.000000  0.733183  \n",
       "4      0.0  0.179389   83  0.0  0.820611  0.000000  0.000000  \n",
       "...    ...       ...  ...  ...       ...       ...       ...  \n",
       "46430  0.0  0.010000   55  0.0  0.147621  0.842379  0.000000  \n",
       "46431  0.0  0.186476   83  0.0  0.758250  0.000000  0.055274  \n",
       "46432  0.0  0.109235   83  0.0  0.890765  0.000000  0.000000  \n",
       "46433  0.0  0.001278   83  0.0  0.931571  0.067151  0.000000  \n",
       "46434  0.0  0.139281   41  0.0  0.860719  0.000000  0.000000  \n",
       "\n",
       "[46435 rows x 156 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>post_created</th>\n",
       "      <th>dc</th>\n",
       "      <th>wt</th>\n",
       "      <th>language</th>\n",
       "      <th>friends</th>\n",
       "      <th>followers</th>\n",
       "      <th>statuses</th>\n",
       "      <th>lists</th>\n",
       "      <th>account_created</th>\n",
       "      <th>profile_language</th>\n",
       "      <th>source</th>\n",
       "      <th>profile_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94</td>\n",
       "      <td>-0.931228</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>en</td>\n",
       "      <td>0.263466</td>\n",
       "      <td>0.333942</td>\n",
       "      <td>0.462209</td>\n",
       "      <td>-0.809151</td>\n",
       "      <td>0.703763</td>\n",
       "      <td>en</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>-0.931237</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>pt</td>\n",
       "      <td>-0.113006</td>\n",
       "      <td>0.030997</td>\n",
       "      <td>0.646550</td>\n",
       "      <td>-0.879588</td>\n",
       "      <td>-0.951713</td>\n",
       "      <td>pt</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106</td>\n",
       "      <td>-0.931241</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>en</td>\n",
       "      <td>0.528658</td>\n",
       "      <td>0.523527</td>\n",
       "      <td>0.529468</td>\n",
       "      <td>-0.111957</td>\n",
       "      <td>-0.581559</td>\n",
       "      <td>en</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>-0.931250</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>en</td>\n",
       "      <td>0.123284</td>\n",
       "      <td>-0.070287</td>\n",
       "      <td>0.259564</td>\n",
       "      <td>-0.688739</td>\n",
       "      <td>0.011612</td>\n",
       "      <td>en</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>147</td>\n",
       "      <td>-0.931238</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>en</td>\n",
       "      <td>0.299875</td>\n",
       "      <td>0.312595</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.554423</td>\n",
       "      <td>-0.227811</td>\n",
       "      <td>en</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46430</th>\n",
       "      <td>35</td>\n",
       "      <td>-0.995000</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>pt</td>\n",
       "      <td>-0.042921</td>\n",
       "      <td>-0.463031</td>\n",
       "      <td>0.161453</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.464452</td>\n",
       "      <td>es</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46431</th>\n",
       "      <td>115</td>\n",
       "      <td>-0.995055</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>en</td>\n",
       "      <td>0.310309</td>\n",
       "      <td>0.138039</td>\n",
       "      <td>0.619081</td>\n",
       "      <td>-0.618303</td>\n",
       "      <td>0.402051</td>\n",
       "      <td>en</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46432</th>\n",
       "      <td>49</td>\n",
       "      <td>-0.995008</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>0.056590</td>\n",
       "      <td>-0.205291</td>\n",
       "      <td>0.414067</td>\n",
       "      <td>-0.720412</td>\n",
       "      <td>-0.818716</td>\n",
       "      <td>en</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46433</th>\n",
       "      <td>132</td>\n",
       "      <td>-0.995039</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>en</td>\n",
       "      <td>0.228311</td>\n",
       "      <td>0.144375</td>\n",
       "      <td>0.849746</td>\n",
       "      <td>-0.720412</td>\n",
       "      <td>0.777447</td>\n",
       "      <td>pt</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46434</th>\n",
       "      <td>116</td>\n",
       "      <td>-0.994994</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>fr</td>\n",
       "      <td>-0.133073</td>\n",
       "      <td>-0.136655</td>\n",
       "      <td>0.362956</td>\n",
       "      <td>-0.809151</td>\n",
       "      <td>-0.630801</td>\n",
       "      <td>fr</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46435 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  post_created  dc  wt language   friends  followers  statuses  \\\n",
       "0         94     -0.931228  11  27       en  0.263466   0.333942  0.462209   \n",
       "1         40     -0.931237  10  13       pt -0.113006   0.030997  0.646550   \n",
       "2        106     -0.931241  11  11       en  0.528658   0.523527  0.529468   \n",
       "3         29     -0.931250  11  30       en  0.123284  -0.070287  0.259564   \n",
       "4        147     -0.931238  11  14       en  0.299875   0.312595  1.000000   \n",
       "...      ...           ...  ..  ..      ...       ...        ...       ...   \n",
       "46430     35     -0.995000  11  21       pt -0.042921  -0.463031  0.161453   \n",
       "46431    115     -0.995055  11  29       en  0.310309   0.138039  0.619081   \n",
       "46432     49     -0.995008  10   1       en  0.056590  -0.205291  0.414067   \n",
       "46433    132     -0.995039  11  27       en  0.228311   0.144375  0.849746   \n",
       "46434    116     -0.994994  11  21       fr -0.133073  -0.136655  0.362956   \n",
       "\n",
       "          lists  account_created profile_language               source  \\\n",
       "0     -0.809151         0.703763               en   Twitter for iPhone   \n",
       "1     -0.879588        -0.951713               pt  Twitter for Android   \n",
       "2     -0.111957        -0.581559               en   Twitter for iPhone   \n",
       "3     -0.688739         0.011612               en  Twitter for Android   \n",
       "4     -0.554423        -0.227811               en   Twitter for iPhone   \n",
       "...         ...              ...              ...                  ...   \n",
       "46430 -1.000000        -0.464452               es   Twitter for iPhone   \n",
       "46431 -0.618303         0.402051               en   Twitter for iPhone   \n",
       "46432 -0.720412        -0.818716               en   Twitter for iPhone   \n",
       "46433 -0.720412         0.777447               pt  Twitter for Android   \n",
       "46434 -0.809151        -0.630801               fr  Twitter for Android   \n",
       "\n",
       "       profile_location  \n",
       "0                    -1  \n",
       "1                    -1  \n",
       "2                   106  \n",
       "3                    29  \n",
       "4                   144  \n",
       "...                 ...  \n",
       "46430                35  \n",
       "46431               115  \n",
       "46432                49  \n",
       "46433               132  \n",
       "46434                -1  \n",
       "\n",
       "[46435 rows x 13 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3. Codierung der verbleibenden Merkmale</h2>\n",
    "\n",
    "Wir nutzen einfache Label-Encodings für die Konvertierung der kategorischen Achsen. Ein Label Encoder codiert kategorische Werte dabei in eine fortlaufende numerische Ganzzahl. Alternativ sind hier One-Hot-Encoding, Binärencoding o.ä. möglich. **Die hier trainierten Encoder müssen zwangsläufig auf der Festplatte abgespeichert werden, damit sie für den Anwendungsbetrieb zur Verfügung stehen.**\n",
    "\n",
    "Die erste Konvertierung betrifft die Sprachkomponente von Tweets, welche momentan in zwei Spalten abgebildet ist, namentlich *language*, also der von Twitter bereitgestellten Sprache und in *profile_language*, d.h. die durch das Sprachensemble berechnete Sprache des Profilinhalts von Nutzern. Sollte im Profil eine Sprache erkannt werden, welche zuvor in den *language*-Objekten der Tweet noch nie gesehen wurden, so wird diese Sprache vor der Codierung der Einfachheit halber auf den rauschbehafteten \"en\"-Sprachtag abgeändert (vgl. Auswertungen zur Merkmalskorrelation). Dies reduziert die Anzahl an unterschiedlichen Sprachlabels für den Klassifikator.\n",
    "\n",
    "Mit Hilfe der Methode *encoder.transform(data)* kann ein Array von kategorischen Daten in einen numerischen Vektor transformiert werden, wenn der Encoder zuvor trainiert wurde und alle im Array vorkommenden Werte bekannt sind, d.h. zuvor beobachtet wurden. Umgekehrt könnte das codierte Array auch wieder in eine String-Repräsentation zurück übersetzt werden (bspw. wenn eine händische Inspektion der Datenpunkte gewünscht ist). Hierzu existiert eine entsprechende *encoder.inverse_transform(encoded_data)* Funktion, die hier im Code aber nicht genutzt wird.\n",
    "\n",
    "Die zweite Konvertierung ist bei der Quellplattform, d.h. der Spalte *source*, notwendig. Auch hier nutzen wir, ähnlich wie bei der Sprachkodierung, einen kleinen Trick, um die Zahl der resultierenden Labels gering zu halten (ist hier zwangsläufig notwendig, da wir mit sehr wenig Trainingsdaten arbeiten). Hierzu werden die beobachtbaren Werte der *source*-Kategorie durch die Funkion *value_counts()* aufgelistet und gezählt. Wir beschränken uns dann auf die häufigsten $9$ beobachtbaren Quellplattformen. Alle anderen Plattformen werden kollektiv auf einen Defaultwert *other* abgebildet. Durch diese Abbildung existieren somit insgesamt $10$ verschiedene Quellplattformen. Diese werden entsprechend durch einen weiteren Label Encoder in numerische Werte übersetzt.\n",
    "\n",
    "Am Ende der Zelle wird die nun fertig vorverarbeitete Eingangsmatrix *df_feat* gezeigt. Theoretisch könnten Spalten mit Ganzzahlen, bspw. die der Encodings, noch auf einen Wertebereich $\\in [-1; 1]$ normalisiert werden. Dies wird hier jedoch übergangen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>post_created</th>\n",
       "      <th>dc</th>\n",
       "      <th>wt</th>\n",
       "      <th>language</th>\n",
       "      <th>friends</th>\n",
       "      <th>followers</th>\n",
       "      <th>statuses</th>\n",
       "      <th>lists</th>\n",
       "      <th>account_created</th>\n",
       "      <th>profile_language</th>\n",
       "      <th>source</th>\n",
       "      <th>profile_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94</td>\n",
       "      <td>-0.931228</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0.263466</td>\n",
       "      <td>0.333942</td>\n",
       "      <td>0.462209</td>\n",
       "      <td>-0.809151</td>\n",
       "      <td>0.703763</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>-0.931237</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.113006</td>\n",
       "      <td>0.030997</td>\n",
       "      <td>0.646550</td>\n",
       "      <td>-0.879588</td>\n",
       "      <td>-0.951713</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106</td>\n",
       "      <td>-0.931241</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.528658</td>\n",
       "      <td>0.523527</td>\n",
       "      <td>0.529468</td>\n",
       "      <td>-0.111957</td>\n",
       "      <td>-0.581559</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>-0.931250</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0.123284</td>\n",
       "      <td>-0.070287</td>\n",
       "      <td>0.259564</td>\n",
       "      <td>-0.688739</td>\n",
       "      <td>0.011612</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>147</td>\n",
       "      <td>-0.931238</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.299875</td>\n",
       "      <td>0.312595</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.554423</td>\n",
       "      <td>-0.227811</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46430</th>\n",
       "      <td>35</td>\n",
       "      <td>-0.995000</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.042921</td>\n",
       "      <td>-0.463031</td>\n",
       "      <td>0.161453</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.464452</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46431</th>\n",
       "      <td>115</td>\n",
       "      <td>-0.995055</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0.310309</td>\n",
       "      <td>0.138039</td>\n",
       "      <td>0.619081</td>\n",
       "      <td>-0.618303</td>\n",
       "      <td>0.402051</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46432</th>\n",
       "      <td>49</td>\n",
       "      <td>-0.995008</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.056590</td>\n",
       "      <td>-0.205291</td>\n",
       "      <td>0.414067</td>\n",
       "      <td>-0.720412</td>\n",
       "      <td>-0.818716</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46433</th>\n",
       "      <td>132</td>\n",
       "      <td>-0.995039</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0.228311</td>\n",
       "      <td>0.144375</td>\n",
       "      <td>0.849746</td>\n",
       "      <td>-0.720412</td>\n",
       "      <td>0.777447</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46434</th>\n",
       "      <td>116</td>\n",
       "      <td>-0.994994</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.133073</td>\n",
       "      <td>-0.136655</td>\n",
       "      <td>0.362956</td>\n",
       "      <td>-0.809151</td>\n",
       "      <td>-0.630801</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46435 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  post_created  dc  wt  language   friends  followers  statuses  \\\n",
       "0         94     -0.931228  11  27         2  0.263466   0.333942  0.462209   \n",
       "1         40     -0.931237  10  13         6 -0.113006   0.030997  0.646550   \n",
       "2        106     -0.931241  11  11         2  0.528658   0.523527  0.529468   \n",
       "3         29     -0.931250  11  30         2  0.123284  -0.070287  0.259564   \n",
       "4        147     -0.931238  11  14         2  0.299875   0.312595  1.000000   \n",
       "...      ...           ...  ..  ..       ...       ...        ...       ...   \n",
       "46430     35     -0.995000  11  21         6 -0.042921  -0.463031  0.161453   \n",
       "46431    115     -0.995055  11  29         2  0.310309   0.138039  0.619081   \n",
       "46432     49     -0.995008  10   1         2  0.056590  -0.205291  0.414067   \n",
       "46433    132     -0.995039  11  27         2  0.228311   0.144375  0.849746   \n",
       "46434    116     -0.994994  11  21         4 -0.133073  -0.136655  0.362956   \n",
       "\n",
       "          lists  account_created  profile_language  source  profile_location  \n",
       "0     -0.809151         0.703763                 2       7                -1  \n",
       "1     -0.879588        -0.951713                 6       5                -1  \n",
       "2     -0.111957        -0.581559                 2       7               106  \n",
       "3     -0.688739         0.011612                 2       5                29  \n",
       "4     -0.554423        -0.227811                 2       7               144  \n",
       "...         ...              ...               ...     ...               ...  \n",
       "46430 -1.000000        -0.464452                 3       7                35  \n",
       "46431 -0.618303         0.402051                 2       7               115  \n",
       "46432 -0.720412        -0.818716                 2       7                49  \n",
       "46433 -0.720412         0.777447                 6       5               132  \n",
       "46434 -0.809151        -0.630801                 4       5                -1  \n",
       "\n",
       "[46435 rows x 13 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode language\n",
    "selected_languages = df_feat[\"language\"].unique()\n",
    "df_feat[\"profile_language\"] = df_feat[\"profile_language\"].apply(lambda n: n if n in selected_languages else \"en\")\n",
    "\n",
    "language_encoder = LabelEncoder().fit(selected_languages)\n",
    "df_feat[\"language\"] = language_encoder.transform(df_feat[\"language\"])\n",
    "df_feat[\"profile_language\"] = language_encoder.transform(df_feat[\"profile_language\"])\n",
    "\n",
    "pickle.dump(language_encoder, open(\"language_encoder.pcl\", \"wb\"))\n",
    "\n",
    "# encode source\n",
    "selected_sources = list(df_feat[\"source\"].value_counts().keys()[:9])  # value counts werden per default sortiert\n",
    "df_feat[\"source\"] = df_feat[\"source\"].apply(lambda n: n if n in selected_sources else \"other\")\n",
    "selected_sources.append(\"other\")\n",
    "\n",
    "source_encoder = LabelEncoder().fit(selected_sources)\n",
    "df_feat[\"source\"] = source_encoder.transform(df_feat[\"source\"])\n",
    "\n",
    "pickle.dump(source_encoder, open(\"source_encoder.pcl\", \"wb\"))\n",
    "\n",
    "df_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier eine exemplarische Rücktransformation von Encodings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       label  post_created  dc  wt language   friends  followers  statuses  \\\n",
      "0         94     -0.931228  11  27       en  0.263466   0.333942  0.462209   \n",
      "1         40     -0.931237  10  13       pt -0.113006   0.030997  0.646550   \n",
      "2        106     -0.931241  11  11       en  0.528658   0.523527  0.529468   \n",
      "3         29     -0.931250  11  30       en  0.123284  -0.070287  0.259564   \n",
      "4        147     -0.931238  11  14       en  0.299875   0.312595  1.000000   \n",
      "...      ...           ...  ..  ..      ...       ...        ...       ...   \n",
      "46430     35     -0.995000  11  21       pt -0.042921  -0.463031  0.161453   \n",
      "46431    115     -0.995055  11  29       en  0.310309   0.138039  0.619081   \n",
      "46432     49     -0.995008  10   1       en  0.056590  -0.205291  0.414067   \n",
      "46433    132     -0.995039  11  27       en  0.228311   0.144375  0.849746   \n",
      "46434    116     -0.994994  11  21       fr -0.133073  -0.136655  0.362956   \n",
      "\n",
      "          lists  account_created  profile_language  source  profile_location  \n",
      "0     -0.809151         0.703763                 2       7                -1  \n",
      "1     -0.879588        -0.951713                 6       5                -1  \n",
      "2     -0.111957        -0.581559                 2       7               106  \n",
      "3     -0.688739         0.011612                 2       5                29  \n",
      "4     -0.554423        -0.227811                 2       7               144  \n",
      "...         ...              ...               ...     ...               ...  \n",
      "46430 -1.000000        -0.464452                 3       7                35  \n",
      "46431 -0.618303         0.402051                 2       7               115  \n",
      "46432 -0.720412        -0.818716                 2       7                49  \n",
      "46433 -0.720412         0.777447                 6       5               132  \n",
      "46434 -0.809151        -0.630801                 4       5                -1  \n",
      "\n",
      "[46435 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "df_feat[\"language\"] = language_encoder.inverse_transform(df_feat[\"language\"])\n",
    "print(df_feat)\n",
    "df_feat[\"language\"] = language_encoder.transform(df_feat[\"language\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 4. Implementierung des gestapelten Klassifikators für Kontextmerkmale</h2>\n",
    "\n",
    "Es müssen hier insgesamt fünf Modelle trainiert werden, eines für Ebene 1 (Kontinente) mit Labels der vier Clustern. Vier weitere, die jeweils nur Datenpunkte aus einem dieser vier Cluster erkennen und hochfrequentere Strukturen und Ergebnisse, d.h. eine Kategorisierung auf Polygon-ID-Ebene durchführen müssen.\n",
    "\n",
    "Wir beginnen mit dem Kontinentalmodell. Da in den Vorarbeiten bereits ausführliche Untersuchungen von möglichen Klassifikatormodellen getätigt wurden, werden diese Codefragmente im Folgenden übersprungen. Somit konzentrieren wir uns auf den verhältnismäßig kurzen Ergebnisteil.\n",
    "\n",
    "Zunächst werden Merkmalsmatrix *df_feat* und Zielvektor *df_labels* in entsprechende Variablen *X* und *y* kopiert. Dies hat den Vorteil, dass der ursprüngliche Datensatz bei der Veränderung der temporären Variablen unberührt bleibt und dieser somit für die nachfolgenden Klassifikatoren wieder verwendet werden kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    36384\n",
       "1     7020\n",
       "3     2906\n",
       "0      125\n",
       "Name: 4, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_feat\n",
    "y = df_labels[\"4\"]\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie ersichtlich, sind die Datenpunkte für diesen kleinen Beispieldatensatz verhältnismäßig unausgewogen bzgl. Größe, ein Samplebalancing sollte also angewandt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    36384\n",
       "2    36384\n",
       "1    36384\n",
       "0    36384\n",
       "Name: 4, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balancer = SMOTE()\n",
    "X, y = balancer.fit_resample(X, y)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>post_created</th>\n",
       "      <th>dc</th>\n",
       "      <th>wt</th>\n",
       "      <th>language</th>\n",
       "      <th>friends</th>\n",
       "      <th>followers</th>\n",
       "      <th>statuses</th>\n",
       "      <th>lists</th>\n",
       "      <th>account_created</th>\n",
       "      <th>profile_language</th>\n",
       "      <th>source</th>\n",
       "      <th>profile_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94</td>\n",
       "      <td>-0.931228</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0.263466</td>\n",
       "      <td>0.333942</td>\n",
       "      <td>0.462209</td>\n",
       "      <td>-0.809151</td>\n",
       "      <td>0.703763</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>-0.931237</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.113006</td>\n",
       "      <td>0.030997</td>\n",
       "      <td>0.646550</td>\n",
       "      <td>-0.879588</td>\n",
       "      <td>-0.951713</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106</td>\n",
       "      <td>-0.931241</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.528658</td>\n",
       "      <td>0.523527</td>\n",
       "      <td>0.529468</td>\n",
       "      <td>-0.111957</td>\n",
       "      <td>-0.581559</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>-0.931250</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0.123284</td>\n",
       "      <td>-0.070287</td>\n",
       "      <td>0.259564</td>\n",
       "      <td>-0.688739</td>\n",
       "      <td>0.011612</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>147</td>\n",
       "      <td>-0.931238</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.299875</td>\n",
       "      <td>0.312595</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.554423</td>\n",
       "      <td>-0.227811</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145531</th>\n",
       "      <td>128</td>\n",
       "      <td>-0.949701</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.066147</td>\n",
       "      <td>-0.141182</td>\n",
       "      <td>0.403878</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.561951</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145532</th>\n",
       "      <td>20</td>\n",
       "      <td>-0.985942</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0.251187</td>\n",
       "      <td>0.566083</td>\n",
       "      <td>0.561659</td>\n",
       "      <td>-0.378456</td>\n",
       "      <td>-0.012570</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145533</th>\n",
       "      <td>20</td>\n",
       "      <td>-0.969095</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.057592</td>\n",
       "      <td>0.008485</td>\n",
       "      <td>0.725709</td>\n",
       "      <td>-0.625448</td>\n",
       "      <td>0.737300</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145534</th>\n",
       "      <td>144</td>\n",
       "      <td>-0.982295</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.196338</td>\n",
       "      <td>-0.337915</td>\n",
       "      <td>0.566578</td>\n",
       "      <td>-0.868163</td>\n",
       "      <td>-0.426169</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145535</th>\n",
       "      <td>128</td>\n",
       "      <td>-0.956655</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.127497</td>\n",
       "      <td>0.078420</td>\n",
       "      <td>0.640038</td>\n",
       "      <td>-0.936746</td>\n",
       "      <td>0.330376</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145536 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label  post_created  dc  wt  language   friends  followers  statuses  \\\n",
       "0          94     -0.931228  11  27         2  0.263466   0.333942  0.462209   \n",
       "1          40     -0.931237  10  13         6 -0.113006   0.030997  0.646550   \n",
       "2         106     -0.931241  11  11         2  0.528658   0.523527  0.529468   \n",
       "3          29     -0.931250  11  30         2  0.123284  -0.070287  0.259564   \n",
       "4         147     -0.931238  11  14         2  0.299875   0.312595  1.000000   \n",
       "...       ...           ...  ..  ..       ...       ...        ...       ...   \n",
       "145531    128     -0.949701  10  13         2 -0.066147  -0.141182  0.403878   \n",
       "145532     20     -0.985942  10  21         2  0.251187   0.566083  0.561659   \n",
       "145533     20     -0.969095  10  21         2 -0.057592   0.008485  0.725709   \n",
       "145534    144     -0.982295  10  14         2 -0.196338  -0.337915  0.566578   \n",
       "145535    128     -0.956655  10  15         2 -0.127497   0.078420  0.640038   \n",
       "\n",
       "           lists  account_created  profile_language  source  profile_location  \n",
       "0      -0.809151         0.703763                 2       7                -1  \n",
       "1      -0.879588        -0.951713                 6       5                -1  \n",
       "2      -0.111957        -0.581559                 2       7               106  \n",
       "3      -0.688739         0.011612                 2       5                29  \n",
       "4      -0.554423        -0.227811                 2       7               144  \n",
       "...          ...              ...               ...     ...               ...  \n",
       "145531 -1.000000        -0.561951                 2       5               128  \n",
       "145532 -0.378456        -0.012570                 2       7                20  \n",
       "145533 -0.625448         0.737300                 2       7                -1  \n",
       "145534 -0.868163        -0.426169                 2       5                -1  \n",
       "145535 -0.936746         0.330376                 2       5               128  \n",
       "\n",
       "[145536 rows x 13 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der Merkmalsmatrix kann nicht erkannt werden, ob es sich um einen realen oder synthetischen Datenpunkt handelt.\n",
    "\n",
    "Somit ist es an der Zeit den gestapelten Klassifikator zu definieren. Hierzu erstellt man zunächst eine *estimator_list*, die Tupel der Form *(identifikator, modell)* enthält. *Identifikator* bezieht sich hierbei auf eine selbst gewählte String-Repräsentation des Modells/der Modellgruppe, die beispielsweise dazu genutzt werden kann, um bei gridbasierten CV-Verfahren Parameterranges für Hyperparameter festzulegen. *Modell* wiederum muss eine Instanz eines einfachen oder zusammengesetzten Klassifikators im Sinne der sklearn-Objekthierarchie sein. Diesem Modell können entweder direkt oder über den zugewiesenen *identifikator* Parametrisierungen übergeben werden.\n",
    "\n",
    "Die *estimator_list* bezieht sich auf die erste Ebene des gestapelten Klassifikators, d.h. einer Zusammenfügung als einem globalen Multiclass-Modells und vielen lokalen Modellen. Wir beginnen bei der Erklärung des Codes mit dem einfacheren globalen Modell. Wie unten ersichtlich wird dieser als ein konventionelles Bagging-Modell instanziiert, welches intern $200$ Schätzer (standardmäßig Entscheidungsbäume) verwendet. Gleichzeitig erlaubt der Parameter *n_jobs* ein parallelisiertes Training mit bis zu *n_jobs* simulatenen Prozessen ($-1$ bedeutet hier alle verfügbaren Cores). Es sei jedoch angemerkt, dass bei solch gestapelten Modellen die maximale Prozesszahl teilweise vom übergeordneten Modell geerbt bzw. beschränkt wird.\n",
    "\n",
    "Ähnlich wie beim globalen Modell könnte nun auch pro Zielklasse ein lokales Modell der *estimator_list* beigefügt werden. Der In- bzw. Output des Klassifikators ist jedoch eine Multiclass-Vorhersage, weswegen dieser Klassifikationstyp von jedem Teilmodell geerbt wird. Würden nun also vier lokale Modelle *locals$_1$*, ...*locals$_4$* eingefügt werden, würde jedes Modell eine dem globalen Klassifikator gleichwertige Multiclass-Klassifikation durchführen - nicht das Ziel unserer Auswertungen.\n",
    "\n",
    "Für eine derartige Klassifikationsaufgabe existiert jedoch praktischerweise eine vordefinierte Wrapper-Klasse, der sog. *OneVsAllClassifier*, vgl. https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html. Diesem Wrapper muss ein konkreten Klassifikatormodell übergeben werden, welches als lokaler Klassifikator verwendet werden soll. Beim Training des Modells, d.h. beim Aufruf der *fit()* Funktion werden dann so viele lokale Klassifikatoren gespawnt, wie es unterschiedliche Zielklassen gibt. Der Wrapper kümmert sich hierbei selbstständig um die Konvertierung der Klassenlabels für jedes individuelle Modell. Gleichzeitig kümmert sich der Wrapper um das Ensembling der Teilergebnisse jedes lokalen Modells. Jedoch kann jedes lokale Modell auch händisch referenziert und evaluiert werden.\n",
    "\n",
    "Nach der Definition der *estimator_list*, das heißt der Menge an Modellen auf der oberen Ebene des gestapelten Klassifikators muss dieser selbst noch erstellt werden. Auch hierfür existiert ein gleichnamiger Wrapper *StackingClassifier*. Diesem muss zunächst die Liste an Teilmodellen, sowie ein Ensembling-Verfahren zur Zusammenführung aller Teilergebnisse als *final_estimator* übergeben werden. Es sei angemerkt, dass ein Estimator des StackingClassifiers auch wieder ein StackingClassifier sein kann, wodurch ein Stacking Classifier mit mehreren Ebenen, ähnlich einem Neuronalen Netz, jedoch mit unterschiedlichen Aktivierungen, entstehen würde.\n",
    "\n",
    "Als interessant gestalten sich die für den StackingClassifier verfügbaren Parameter. Insbesondere soll hier kurz über drei Werte diskutiert werden. Die *stack_method* bezieht sich dabei auf den Vorhersagetyp des Klassifikators. Konventionell wird ein vortrainiertes Modell mit einem der beiden Funktionen *predict()* oder *predict_proba()* angewandt, d.h. die Vorhersage ist entweder diskretisiert oder eben eine Wahrscheinlichkeitsverteilung über alle Zielklassen. Nun existiert jedoch nicht für jedes Klassifikatormodell die (informativere) probabilistische Vorhersage. In der *stack_method* muss nun angegeben werden, auf welche Ausgabe der Gesamtklassifikator trainiert werden soll. Im hier übergebenen Modus *auto* wird zunächst, falls alle Estimator diese Funktion implementieren, die *predict_proba()* Variante bevorzugt.\n",
    "\n",
    "Der Parameter *passthrough* bezieht sich darauf, ob die auf erster Ebene eingegeben Merkmale, neben den Vorhersagen der *estimator_list*, an den *final_estimator* übergeben werden sollen, oder nicht. Wir entscheiden uns aktiv gegen diese Option, da somit die gesamte Aussagekraft des Modells durch die Vorhersagen der lokalen Modelle kommen **muss** und die Vorhersage nicht (im worst case) in eine Logistische Regression des Eingabevektors mit 0-Gewichten der vorherigen *estimator_list* degeneriert.\n",
    "\n",
    "Schließlich kann eine automatisch durchgeführte Kreuzvalidierung des *final_estimators* angestoßen werden, wenn eine Zahl *N* an gewünschten Folds an den *cv* Parameter übergeben wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_list = [(\"locals\", OneVsRestClassifier(estimator=AdaBoostClassifier(n_estimators=10), n_jobs=-1)), \n",
    "                ('global', BaggingClassifier(n_estimators=10, n_jobs=-1))]\n",
    "\n",
    "model = StackingClassifier(estimators=estimator_list, \n",
    "                           final_estimator=LogisticRegression(),\n",
    "                           stack_method=\"auto\",\n",
    "                           passthrough=False,\n",
    "                           cv=3,\n",
    "                           n_jobs=100,\n",
    "                           verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training und Test des Modells der ersten Ebene kann auf viele Arten durchgeführt werden. Folgender Code reduziert sich auf das Minimum und vermeidet komplexere, aber statistisch fundiertere Ergebnisse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete, took 5 seconds.\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "t0 = time.time()\n",
    "# model.fit(X_train, y_train)\n",
    "model.fit(X[:30000], y[:30000])\n",
    "\n",
    "print(\"Training complete, took {} seconds.\".format(round(time.time()-t0), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8823050823985598"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.score(X_test, y_test)\n",
    "model.score(X[30000:], y[30000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Modellqualitäten sind aufgrund der Datenmenge mit Vorsicht zu genießen, der Code ist jedoch auch auf größeren Eingabematrizen korrekt. Wollen wir nun einen einzelnen Tweet vorhersagen, so wäre das Ergebnis des ersten Klassifikators für Kontextmerkmale beispielsweise folgender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.62126577e-04, 4.01120070e-03, 9.93619118e-01, 2.10755427e-03]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X.to_numpy()[0].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch könnte lediglich einer der lokalen Klassifikatoren gefragt werden, ob dieser den Datenpunkt kennt oder nicht. Die Referenzierung des Teilmodells erfolgt hier durch das *estimators_* Objekt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.80238137, 0.19761863]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimators_[0].estimators_[0].predict_proba(X.to_numpy()[0].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ist man mit dem Modell zufrieden, sollte dieses persistiert werden.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open(\"model_l1.pcl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die gleiche Trainingsprozedur kann nun für die verbleibenden vier Modelle angestoßen werden. Wichtig ist nun jedoch, dass jedes Modell der zweiten Ebene nur auf denjenigen Datenpunkten trainiert wird, die auch wirklich in seinen Bereich fallen. Konkret bedeutet dies, dass das Teilmodell, welches sich auf den \"Kontinent\" Nordamerika beschränken soll, nicht mit Trainingsdaten aus europäischen Polygonen arbeiten sollte. Um dies zur erreichen wird zu Beginn jeder Iteration (eine Iteration trainiert genau einen Teilklassifikator) auf das entsprechende Subset an Datenpunkten gefiltert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:03,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 2 - Cluster 0: 0.8295454545454546 acc (2.65s duration)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:14,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 2 - Cluster 1: 0.9922669922669922 acc (9.68s duration)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:28,  8.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 2 - Cluster 2: 0.9999214731634536 acc (11.2s duration)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:37,  9.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 2 - Cluster 3: 0.9852579852579852 acc (8.58s duration)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i, c in tqdm(enumerate(np.bincount(df_labels[\"4\"]))):\n",
    "\n",
    "    # Filtern auf die relevante Teilmenge an Datenpunkten\n",
    "    X = df_feat[df_labels[\"4\"] == i]\n",
    "    y = df_labels[df_labels[\"4\"] == i]\n",
    "    y = y[\"150\"]\n",
    "    \n",
    "    # Rebalancing\n",
    "    \"\"\"\n",
    "    try:\n",
    "        balancer = SMOTE()\n",
    "        X, y = balancer.fit_resample(X, y)\n",
    "    except:\n",
    "        print(\"Too few datapoints in classes: {}\".format(np.bincount(y)))\n",
    "        balancer = RandomOverSampler()\n",
    "        X, y = balancer.fit_resample(X, y)\n",
    "    \"\"\"\n",
    "\n",
    "    # train-test split\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, stratify=y)\n",
    "    X_train = X[:int(X.shape[0] * 0.3)]\n",
    "    X_test = X[int(X.shape[0] * 0.3):]\n",
    "    y_train = y[:int(X.shape[0] * 0.3)]\n",
    "    y_test = y[int(X.shape[0] * 0.3):]\n",
    "    \n",
    "    # Klassifikatormodell wie oben\n",
    "    estimator_list = [(\"locals\", OneVsRestClassifier(estimator=AdaBoostClassifier(n_estimators=5), n_jobs=-1)), \n",
    "                    ('global', BaggingClassifier(n_estimators=5, n_jobs=-1))]\n",
    "\n",
    "    model = StackingClassifier(estimators=estimator_list, \n",
    "                               final_estimator=LogisticRegression(),\n",
    "                               stack_method=\"auto\",\n",
    "                               passthrough=False,\n",
    "                               n_jobs=100,\n",
    "                               verbose=1)\n",
    "\n",
    "    # Training\n",
    "    t0 = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    # Scoring\n",
    "    score = model.score(X_test, y_test)\n",
    "    \n",
    "    # Modell persistieren\n",
    "    pickle.dump(model, open(\"model_l2_c{}.pcl\".format(i), \"wb\"))\n",
    "    \n",
    "    print(\"Layer 2 - Cluster {}: {} acc ({}s duration)\\n\".format(i, score, round(t1-t0, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 5. Implementierung des Ensemblings für Kontext- und Kontentergebnisse</h2>\n",
    "\n",
    "Das Ensembling funktioniert relativ simpel: es kann als logistische Regression der Outputs von Kontext- und Kontentfeatures dargestellt werden. Prinzipiell könnte die gesamte Architektur als ein in sich geschlossenes Modell dargestellt werden (durch Schachtelung der oben beschriebenen Stacked Classifiers). Prototypisch kann es jedoch auch als separat trainierter Klassifikator umgesetzt werden, wie hier zu sehen.\n",
    "\n",
    "Wir beginnen wieder mit dem Modell auf oberster Ebene. Für Training und Anwendung klassifzieren wir die gewünschten Datenpunkte zunächst mit dem bereits abgespeicherten Modell *stacked_classifier*. Dank der Methode *predict_proba()* erhalten wir eine Wahrscheinlichkeitsverteilung über die - hier - $4$ Zielklassen. Diese vier Wahrscheinlichkeitswerte korrespondieren zum Kontextoutput der Tweets und werden in die erste Outputvariable *y_1* geschrieben. Da der Text bereits zuvor klassifiziert wurde, können wir die entsprechende W'keitsverteilung direkt aus dem entsprechenden Dataframe auslesen und in die zweite Variable *y_2* schreiben.\n",
    "\n",
    "Für das Ensembling konkatenieren wir *y_1* und *y_2* mit Hilfe der Funktion *np.hstack()*, also \"staple die Vektoren horizontal\" in einen neuen Eingabevektor. Das gewünschte Label dieser beiden Teilergebnisse ist weiterhin der bekannte Vektor *y*.\n",
    "\n",
    "Wie unten ersichtlich, wird die logistische Regression auf den ersten 80% der Datenpunkte trainiert und auf den verbleibenden 20% getestet. Das trainierte Modell wird auch persistier.\n",
    "\n",
    "An dieser Stelle sei vermerkt, dass im Rahmen des Workshops alle Klassifikatoren mit Ausnahme des Textklassifikators neu trainiert wurden. Daher sind die Textvorhersagen auf andere Klassenlabels ausgerichtet und die Werte der Textklassifikation für hier und später sind wenig aussagekräftig. Hier geht es vielmehr um den implementierungstechnischen Aspekt der Zusammenführung beider Teilergebnisse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_feat\n",
    "y = df_labels[\"4\"]\n",
    "\n",
    "stacked_classifier = pickle.load(open(\"model_l1.pcl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.945493700872187 0.346850436093464 0.9766340045224507\n"
     ]
    }
   ],
   "source": [
    "y_1 = stacked_classifier.predict_proba(df_feat)  # get probability distribution for each sample\n",
    "y_2 = df_text[[\"4_0\", \"4_1\", \"4_2\", \"4_3\"]]  # get text probability distribution\n",
    "y = df_labels[\"4\"]  # get target labels\n",
    "\n",
    "N = len(y)\n",
    "meta_res = (np.argmax(y_1, axis=1) == y).value_counts()[1]/N\n",
    "text_res = (np.argmax(y_2.to_numpy(), axis=1) == y).value_counts()[1]/N\n",
    "\n",
    "lr = LogisticRegression().fit(np.hstack((y_1[:int(0.8*N)], y_2[:int(0.8*N)])), y[:int(0.8*N)])\n",
    "combined_res = lr.score(np.hstack((y_1[int(0.8*N):], y_2[int(0.8*N):])), y[int(0.8*N):])\n",
    "\n",
    "print(meta_res, text_res, combined_res)\n",
    "pickle.dump(lr, open(\"ensemble_l1.pcl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Ensembles auf der zweiten Ebene kann prinzipiell wieder der selbe Code genutzt werden, wobei hier nun zusätzliche Arbeit anfällt, um die Labels korrekt miteinander zu vergleichen. Zunächst wird im Label-Dataframe über die vier verschiedenen Cluster iteriert. Jeder Cluster benötigt ein eigenes Modell. Entsprechende Filteroperationen für Kontext-, Kontent- und Label-Dataframes sind eingebaut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.856 0.0 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:00,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.994017094017094 0.019515669515669517 0.9914529914529915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:05,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999175461741425 0.00032981530343007914 0.9995877422014566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:05,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9872677219545767 0.0020646937370956643 0.9845360824742269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i, c in tqdm(enumerate(np.bincount(df_labels[\"4\"]))):\n",
    "\n",
    "    # Filtern auf die relevante Teilmenge an Datenpunkten\n",
    "    X = df_feat[df_labels[\"4\"] == i]\n",
    "    X_text = df_text[df_labels[\"4\"] == i]\n",
    "    y = df_labels[df_labels[\"4\"] == i]\n",
    "    y = y[\"150\"]\n",
    "            \n",
    "    stacked_classifier = pickle.load(open(\"model_l2_c{}.pcl\".format(i), \"rb\"))\n",
    "    \n",
    "    \n",
    "    y_1 = stacked_classifier.predict_proba(X)  # get probability distribution for each sample\n",
    "    y_2 = X_text[\"150\"]  # get text probability distribution\n",
    "    \n",
    "    classes = stacked_classifier.classes_.tolist()\n",
    "    \n",
    "    # y = [classes.index(x) if x in classes else -1 for x in y]\n",
    "    \n",
    "    \n",
    "    N = len(y)\n",
    "    meta_res = np.count_nonzero(np.argmax(y_1, axis=1) == [classes.index(x) if x in classes else -1 for x in y])/N\n",
    "    text_res = np.count_nonzero(y_2 == [classes.index(x) if x in classes else -1 for x in y])/N\n",
    "    \n",
    "    y_2 = X_text[[x for x in classes]]\n",
    "    \n",
    "    lr = LogisticRegression().fit(np.hstack((y_1[:int(0.8*N)], y_2[:int(0.8*N)])), y[:int(0.8*N)])\n",
    "    combined_res = lr.score(np.hstack((y_1[int(0.8*N):], y_2[int(0.8*N):])), y[int(0.8*N):])\n",
    "\n",
    "    print(meta_res, text_res, combined_res)\n",
    "    pickle.dump(lr, open(\"ensemble_l2_c{}.pcl\".format(i), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unten ist noch ein beispielhafter Codeausschnitt, wie die aufbereiteten Tweet Files automatisch ausgewertet werden. Der Code ist den Zeitreihenauswertungen aus Quartal 4 entnommen. Der konkrete Aufbau des Skripts ist hier nahezu identisch zum Training, mit der Änderung, dass nun eben nur die *model.predict_proba()* Methode aufgerufen und händisch mit den Ground Truth Class Labels verglichen wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Automatisierte Klassifikation von Zeitreihen\n",
    "\"\"\"\n",
    "path = \"data/feature_files/\"\n",
    "files = [path + f for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "# Files vorbereiten\n",
    "feature_files = [f for f in files if f[-8:] == \"features\"]\n",
    "geocoding_files = [f for f in files if f[-3:] == \"loc\"]\n",
    "text_files = [f for f in files if f[-8:] == \"pred.npz\"]\n",
    "\n",
    "# Variablen definieren\n",
    "df_feat = None\n",
    "df_text = None\n",
    "df_labels = None\n",
    "\n",
    "\"\"\"\n",
    "Main Loop: Klassifikation für jeden Monat im Datensatz, hier jeweils als eigenes File\n",
    "\"\"\"\n",
    "for feature_file in tqdm(sorted(feature_files, reverse=True)):  # füŕ jedes File\n",
    "    \n",
    "    # Variablen zurücksetzen\n",
    "    df_feat = None\n",
    "    df_text = None\n",
    "    df_labels = None\n",
    "        \n",
    "    file_prefix = feature_file.split(\".\")[0]\n",
    "        \n",
    "    # Filenamen filtern\n",
    "    geo_file = [f for f in geocoding_files if file_prefix in f][0]\n",
    "    text_file = [f for f in text_files if file_prefix in f][0]\n",
    "\n",
    "    \"\"\"\n",
    "    Data Frames erstellen\n",
    "    \"\"\"\n",
    "    # 1. Feature Data Frame\n",
    "    df_feat = pd.read_csv(feature_file, delimiter=\";\")\n",
    "    \n",
    "    print(df_feat)\n",
    "    break\n",
    "    \n",
    "    # Profile Location ist noch in einem anderen File abgespeichert, weil die vorherige Pipeline \n",
    "    # die Daten noch durch den Geocoder prozessieren lassen musste... hier findet der Merge statt\n",
    "    df_geo = pd.read_csv(geo_file)\n",
    "    df_feat[\"profile_location\"] = df_geo[\"profile_location\"]\n",
    "    del df_geo\n",
    "    \n",
    "    # 2. Text Data Frame\n",
    "    df_text = pd.DataFrame(sparse.load_npz(text_file).todense())\n",
    "    \n",
    "    # 3. Label Data Frame\n",
    "    df_labels = pd.DataFrame()\n",
    "    df_labels[\"150\"] = df_feat[\"label\"]\n",
    "    df_feat = df_feat.drop(columns=\"label\")\n",
    "    \n",
    "    \"\"\"\n",
    "    Data Preprocessing: Hierarchielabels extrahieren und Features codieren\n",
    "    \"\"\"\n",
    "    \n",
    "    # Hierarchieebenen definieren\n",
    "    df_labels[\"4\"] = df_labels[\"150\"].apply(lambda n: C4_T[n])\n",
    "    df_labels[\"16\"] = df_labels[\"150\"].apply(lambda n: C16_T[n])\n",
    "    \n",
    "    # Features codieren\n",
    "    # Sprachen auf unser 9 Sprachen-Sample beschränken (unbekannte Sprachen werden auf 'en' gemappt)\n",
    "    selected_languages = df_feat[\"language\"].unique()\n",
    "    df_feat[\"profile_language\"] = df_feat[\"profile_language\"].apply(lambda n: n if n in selected_languages else \"en\")\n",
    "    df_feat[\"language\"] = language_encoder.transform(df_feat[\"language\"])\n",
    "    df_feat[\"profile_language\"] = language_encoder.transform(df_feat[\"profile_language\"])\n",
    "    \n",
    "    # Sources auf bekannte Sources beschränken, ansonsten auf die Wildcard \"other\" mappen\n",
    "    df_feat[\"source\"] = df_feat[\"source\"].apply(lambda n: n if n in source_encoder.classes_ else \"other\")\n",
    "    df_feat[\"source\"] = source_encoder.transform(df_feat[\"source\"])    \n",
    "    \n",
    "    \"\"\"\n",
    "    Text Wahrscheinlichkeiten für Layer 1 und 2 aufbereiten \n",
    "    (Top 10 Klassen mit W'keiten von Layer 0 sind gegeben)\n",
    "    \"\"\"\n",
    "    # Zu Beginn sind die Labels 0..149 mit W'keiten gefüllt, falls sie in den Top 10 sind, sonst mit 0\n",
    "    # Label 150 ist die Gegenw'keit, d.h. 1- Summe(Top10)\n",
    "    \n",
    "    # Diskretisiere Text-Label für Layer 0 via Argmax:\n",
    "    df_text[\"150\"] = df_text.idxmax(axis=1)  # get argmax cluster id for each data point\n",
    "    \n",
    "    # Falls Gegenw'keit > .5, d.h. Vorhersage unsicher war, dann deklariere Datenpunkt als -1, also\n",
    "    # als \"unschlüsslig\"\n",
    "    df_text[\"150\"] = df_text[\"150\"].apply(lambda n: n if n != 150 else -1)  # Top Predictions < .5\n",
    "\n",
    "    # sum the probabilities of subclusters that belong into the same cluster\n",
    "    for i, member in enumerate(C[4]):\n",
    "        df_text[\"4_{}\".format(i)] = 0\n",
    "        for m in member:\n",
    "            df_text[\"4_{}\".format(i)] += df_text[m]\n",
    "\n",
    "    # sum the probabilities of subclusters that belong into the same cluster\n",
    "    for i, member in enumerate(C[16]):\n",
    "        df_text[\"16_{}\".format(i)] = 0\n",
    "        for m in member:\n",
    "            df_text[\"16_{}\".format(i)] += df_text[m]\n",
    "            \n",
    "    \"\"\"\n",
    "    Preprocessing fertig, Auswertungen beginnen ab hier.\n",
    "    Auswertungen führen wir für jedes Layer individuell durch.\n",
    "    \"\"\"\n",
    "        \n",
    "    for layer in range(3):\n",
    "        print(\"Layer:\" + str(layer))\n",
    "        # 1. Modell-Identifikatoren für aktuelles Layer laden\n",
    "        layer_models = [f.split(\"ensemble_\")[-1].split(\".pcl\")[0] for f in listdir(\".\") if isfile(f) and \"ensemble_l{}\".format(layer) in f]\n",
    "        print(\"Models:\" + str(layer_models))\n",
    "        \n",
    "        for model_str in layer_models:\n",
    "            print(\"Current Model:\" + model_str)\n",
    "            # Stacked Classifier laden\n",
    "            model = pickle.load(open(model_str, \"rb\"))\n",
    "            # Text-Ensemble laden\n",
    "            ensemble = pickle.load(open(\"ensemble_\" + model_str + \".pcl\", \"rb\"))\n",
    "            \n",
    "            # 2. Daten filtern auf aktuellen Cluster \n",
    "            # (Modell kann nichts vorhersagen, was es nicht kennt)\n",
    "            \n",
    "            # Gefilterte Dataframes identizieren wir hier mit _ am Ende\n",
    "            df_feat_ = None\n",
    "            df_labels_ = None\n",
    "            df_text_ = None\n",
    "            cluster_id = None\n",
    "            \n",
    "            # müssen hier zwischen Layer 0 und 1 bzw. 2 differenzieren, da die \n",
    "            # unteren Layers mehrere Modelle besitzen (eines pro Cluster)\n",
    "            \n",
    "            if layer == 0:\n",
    "                df_feat_ = df_feat  # kein Filter nötig auf oberster Ebene\n",
    "                df_labels_ = df_labels[\"4\"]  # Layer 0 predicted auf 4 Klassen\n",
    "                df_text_ = df_text[[\"4_0\", \"4_1\", \"4_2\", \"4_3\"]]\n",
    "\n",
    "            elif layer == 1:\n",
    "                cluster_id = int(model_str.split(\"_c\")[-1])\n",
    "                # print(\"CID\", cluster_id)\n",
    "                \n",
    "                df_labels_ = df_labels[df_labels[\"4\"] == cluster_id]  # Filtere auf Cluster-ID\n",
    "                df_feat_ = df_feat[df_labels[\"4\"] == cluster_id]\n",
    "                df_text_ = df_text[df_labels[\"4\"] == cluster_id]\n",
    "                df_labels_ = df_labels_[\"16\"]  # Layer 1 predicted auf 16 Klassen\n",
    "                df_text_ = df_text[[\"16_{}\".format(x) for x in range(16)]]\n",
    "                \n",
    "            elif layer == 2:\n",
    "                cluster_id = int(model_str.split(\"_c\")[-1])\n",
    "                \n",
    "                df_labels_ = df_labels[df_labels[\"16\"] == cluster_id]  # Filtere auf Cluster-ID\n",
    "                df_feat_ = df_feat[df_labels[\"16\"] == cluster_id]\n",
    "                df_text_ = df_text[df_labels[\"16\"] == cluster_id]\n",
    "                \n",
    "                df_labels_ = df_labels_[\"150\"]  # Layer 3 predicted auf 150 Klassen\n",
    "                df_text_ = df_text[[x for x in range(150)]]\n",
    "                            \n",
    "            # 3. Daten vorhersagen\n",
    "            y_hat = model.predict(df_feat_)\n",
    "            result = y_hat == df_labels_\n",
    "            \n",
    "            N = y_hat.shape[0]\n",
    "            meta_res = (y_hat == df_labels_).value_counts()[1]/N\n",
    "            text_res = (np.argmax(df_text_.to_numpy(), axis=1) == df_labels_).value_counts()[1]/N\n",
    "            \n",
    "            y_2= df_text_.idxmax(axis=1).to_numpy()\n",
    "            y_2 = [int(x.split(\"_\")[-1]) for x in y_2]\n",
    "            combined_res = ensemble.score(np.hstack((y_hat[int(0.8*N):], np.ay_2[int(0.8*N):])), df_labels_[int(0.8*N):])\n",
    "\n",
    "            \n",
    "            print(meta_res, text_res, combined_res)\n",
    "    \n",
    "            \n",
    "            print(\"----\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>6. Implementierung des Abstainings</h2>\n",
    "\n",
    "Für das Abstaining muss zunächst eine minimale Sicherheit, also ein Grenzwert pro Zielklasse bestimmt werden. Wir starten dabei mit der Häufigkeitsverteilung der Trainingsdaten auf die einzelnen Cluster und multiplizieren diesen Vektor mit einem immer größer werdenden Skalar. In jeder Iteration wird geprüft, wie sich die Modellqualitäten (Accuracy, NMI, Kappa) verändern. Das Vielfache des Häufigkeitsvektors, welches die besten Modellqualitäten besitzt, wird dann für die nachfolgende Anwendung genutzt. Da im Workshop mit einem zweistufigen Klassifikator gearbeitet wird, müssen lediglich für die oberste Ebene die Schwellwerte berechnet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00269193 0.15117907 0.78354689 0.0625821 ]\n"
     ]
    }
   ],
   "source": [
    "# Berechne Verteilung von Zielklassen\n",
    "dist = np.bincount(df_labels[\"4\"])\n",
    "dist = np.bincount(df_labels[\"4\"]) / np.sum(dist)\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lade relevante Modelle auf Layer 1\n",
    "stacked_classifier = pickle.load(open(\"model_l1.pcl\", \"rb\"))\n",
    "ensemble = pickle.load(open(\"ensemble_l1.pcl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neben der Häufigkeitsverteilung sind noch die Vorhersagen, d.h. die probabilistischen Klassifikationsergebnisse der einzelnen Datenpunkte, sowie (zumindest zur Berechnung des Schwellwertes) die wahren Klsasenlabels erforderlich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.69219144e-04 7.96754301e-03 9.91626653e-01 2.36584999e-04]\n",
      " [4.34043237e-05 8.26124653e-03 9.91485391e-01 2.09958537e-04]\n",
      " [1.31873714e-04 8.32170377e-03 9.91178208e-01 3.68214740e-04]\n",
      " ...\n",
      " [1.59784406e-04 7.47113588e-03 9.92130991e-01 2.38088915e-04]\n",
      " [1.56856601e-04 8.12841617e-03 9.91502374e-01 2.12353025e-04]\n",
      " [1.85453944e-03 9.44772086e-01 4.44592672e-02 8.91410708e-03]]\n",
      "0        2\n",
      "1        2\n",
      "2        2\n",
      "3        2\n",
      "4        2\n",
      "        ..\n",
      "46430    2\n",
      "46431    2\n",
      "46432    2\n",
      "46433    2\n",
      "46434    1\n",
      "Name: 4, Length: 46435, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Berechne vorhergesagte Klassenlabels\n",
    "\n",
    "# Kontextmerkmale\n",
    "y_1 = stacked_classifier.predict_proba(df_feat)\n",
    "y_2 = df_text[[\"4_0\", \"4_1\", \"4_2\", \"4_3\"]]\n",
    "\n",
    "# Ensembling\n",
    "y_pred = ensemble.predict_proba(np.hstack((y_1, y_2)))\n",
    "print(y_pred)\n",
    "\n",
    "\n",
    "# Extrahiere wahre Labels\n",
    "y_true = df_labels[\"4\"]\n",
    "print(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die nachfolgenden beiden Hilfsfunktionen setzen das Abstaining exemplarisch um. Die Funktion *abstain(tau)* nimmt hierzu einen Vektor entgegen, welcher die Schwellwerte aller Zielklassen beinhaltet. Dieser wird auf die Vorhersagen der Trainingsdatenpunkte, welche bereits in der Variable *y_pred* abgespeichert sind, angewandt. Der Output der *abstain(tau)* Funktion ist ein diskretes Klassenlabel. Dies ist entweder das Label, welches am weitesten den Schwellwert überschreitet, oder, falls keine der Klassen sicher genug vorhergesagt werden kann, ein entsprechender Defaultwert von $-1$.\n",
    "\n",
    "Die Funktion *abstain_rate(tau)* wird nur für die nachfolgenden Plots benötigt und liefert den Prozentsatz an Datenpunkten, welcher mit dem übergebenen Schwellwertvektor *tau* nicht mehr klassifiziert werden würde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abstain(tau):\n",
    "    y_abs = []\n",
    "    for row in y_pred:\n",
    "        y_abs.append(np.argmax(row/tau) if np.max(row/tau) > 1 else len(row))\n",
    "    return np.asarray(y_abs)\n",
    "\n",
    "def abstain_rate(tau):\n",
    "    y_abs = abstain(tau)\n",
    "    return y_abs.tolist().count(y_pred.shape[1] ) / y_abs.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bestimmung von $\\tau$**\n",
    "\n",
    "Wir berechnen zunächst die Modellqualitäten (in Form von Acc, NMI und Kappa), falls kein Abstaining angewandt wird. In der zweiten und dritten Zeile werden die Modellqualitäten erneut mit variierenden Werten für $\\tau$ berechnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:11<00:00,  3.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f2f49b77eb8>"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Abstaining with varying Frequency threshold\n",
    "alphas = np.linspace(0.5, 1.5, 35)\n",
    "\n",
    "y1s = []\n",
    "y2s = []\n",
    "y3s = []\n",
    "abstains = []\n",
    "for alpha in tqdm(alphas):\n",
    "    df = pd.DataFrame()\n",
    "    df[\"y_true\"] = y_true\n",
    "    df[\"y_abs\"] = abstain(alpha*dist)\n",
    "\n",
    "    df_ = df[df[\"y_abs\"] != len(dist)]\n",
    "    y1s.append(normalized_mutual_info_score(df_[\"y_true\"], df_[\"y_abs\"]))\n",
    "    y2s.append(cohen_kappa_score(df_[\"y_true\"], df_[\"y_abs\"]))\n",
    "    y3s.append(np.count_nonzero(df_[\"y_true\"] ==  df_[\"y_abs\"]) / df[df[\"y_abs\"] != 4].shape[0])\n",
    "    abstains.append(1 - df_.shape[0] / df.shape[0])\n",
    "\n",
    "plt.plot(abstains, y1s, label=\"NMI\")\n",
    "plt.plot(abstains, y2s, label=\"Kappa\")\n",
    "plt.plot(abstains, y3s, label=\"Accuracy\")\n",
    "plt.xlabel(\"Abstain Rate\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f2f49da3278>"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(alphas, y1s, label=\"NMI\")\n",
    "plt.plot(alphas, y2s, label=\"Kappa\")\n",
    "plt.plot(alphas, y3s, label=\"Accuracy\")\n",
    "plt.xlabel(\"Factor of Frequency Distribution for Abstaining\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir sehen also bereits grafisch, dass grob das $1.25$-fache der Häufigkeitsverteilung optimal hinsichtlich der Modellqualitäten ist. Wir entnehmen in der nächsten Zelle den genauen Wert und berechnen die hierdurch erhaltenen Modellqualitäten von allen verbleibenden Datenpunkten, d.h. diejenigen, welche nach dem Abstaining weiterhin klassifiziert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2647058823529411"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_opt = alphas[np.argmax(y1s)]\n",
    "alpha_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.9865833961451491\n",
      "NMI: 0.8917958071464861\n",
      "Kappa: 0.9623048505124631\n"
     ]
    }
   ],
   "source": [
    "# Result without Abstaining\n",
    "print(\"ACC: {}\".format(np.count_nonzero(y_true == np.argmax(y_pred, axis=1)) / y_pred.shape[0]))\n",
    "print(\"NMI: {}\".format(normalized_mutual_info_score(y_true, np.argmax(y_pred, axis=1))))\n",
    "print(\"Kappa: {}\".format(cohen_kappa_score(y_true, np.argmax(y_pred, axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.9926791324771985\n",
      "NMI: 0.9461483821394397\n",
      "Kappa: 0.98409945303947\n"
     ]
    }
   ],
   "source": [
    "# Results with Abstaining\n",
    "\n",
    "# get abstained results\n",
    "y_abstained = abstain(dist*alpha_opt)\n",
    "\n",
    "# filter on data points that are not omitted\n",
    "y_true_ = y_true[np.where(y_abstained != dist.shape[0])[0]]\n",
    "y_abstained_ = y_abstained[np.where(y_abstained != dist.shape[0])[0]]\n",
    "\n",
    "#print(y_true.shape, y_abstained.shape, y_true_.shape, y_abstained_.shape)\n",
    "# print results again\n",
    "print(\"ACC: {}\".format(np.count_nonzero(y_true_ == y_abstained_) / y_true_.shape[0]))\n",
    "print(\"NMI: {}\".format(normalized_mutual_info_score(y_true_, y_abstained_)))\n",
    "print(\"Kappa: {}\".format(cohen_kappa_score(y_true_, y_abstained_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der nächsten Zelle ist abschließend eine Wrapper-Methode *classify_data()* zu sehen, welche einen vollständigen Klassifikationsschritt durch das hierarchische Modell samt Abstaining durchführt. Die Methode erwartet die Übergabe von drei Parametern:\n",
    "\n",
    "- *X_context* ist die Kontext-Featurematrix\n",
    "- *X_text* ist die Matrix der Textvorhersage\n",
    "- *tau_opt* ist der zuvor berechnete Schwellwertsvektor\n",
    "\n",
    "Im ersten Schritt werden die Klassifikationen auf der ersten Ebene durchgeführt. Hierzu werden zunächst die beiden notwendigen Modelle geladen (gestapelter Klassifikator + Ensembling Modell) und danach die übergebenen Datenmatrizen mittels *predict_proba()* auf den Klassifikatoren vorhergesagt. Wie ersichtlich müssen für das Ensembling-Modell die Kontext- und Text-Teilergebnisse zudem mit Hilfe der Funktion *np.hstack()* zu einem geschlossenen Vektor konkateniert werden.\n",
    "\n",
    "Die Ergebnisse der Vorhersage der ersten Stufe (d.h. die Wahrscheinlichkeitsverteilungen auf die vier Cluster) werden sodann in eine Ausgabevariable *y_pred* geschrieben. Durch den Aufruf der bereits bekannten *abstain()* Methode werden diese probabilistischen Outputs in diskrete Klassenlabels umgewandelt. Der Ausgabewert ist hier entweder die ID eines Clusters, oder aber $-1$, falls kein Cluster den Schwellwert überschreitet.\n",
    "\n",
    "Von diesem Punkt erfolgt die Weiterverarbeitung auf zwei Arten: Alle Datenpunkte, deren Ergebnisse im Sinne des Abstainings zu unsicher sind, werden nicht weiter klassifiziert, d.h. die Ausgabe würde $-1$, also \"Enthaltung\" liefern. Alle anderen Datenpunkte würden nun weiter klassifiziert werden. Dazu müssen die entsprechenden Datenpunkte an das korrekte Modell der zweiten Ebene weitergegeben werden.\n",
    "\n",
    "Die finalen Klassifikationsergebnisse (hier vereinfacht in Form von diskreten Klassenlabels) werden in einer Variable *result* abgespeichert. Zunächst sind die Ausgabewerte aller Datenpunkte auf $-1$, also \"Enthaltung\" gesetzt. Im Laufe der Folgeklassifikationen werden aber alle klassifizierbaren Datenpunkte angepasst.\n",
    "\n",
    "Die eigentlichen Vorhersagen der zweiten Ebene werden in der for-Schleife durchgeführt. Für jedes der vier Modelle (d.h. IDs 0-3) werden die entsprechenden Modelle der zweiten Ebene geladen und es wird auf diejenigen Datenpunkte gefiltert, welche auf Ebene 1 bereits in den korrekten Cluster einsortiert wurden. Nach der Berechnung der Outputs für Kontextmerkmale, der erneuten Kombination von Kontext- und Textergebnisse und der Berechnung des Ensemblings sind erneut in der Variable *y_pred_* die Ergebnisse der zweiten Ebene abgespeichert. Diese werden in den oben genannten *result*-Vektor geschrieben. \n",
    "\n",
    "Einzig neu ist die Konvertierung der Ausgabewahrscheinlichkeiten in die jeweiligen Polygon-IDs. Da Polygon-IDs nicht über die ClusterIDs hinweg sortiert sind, muss mit der temporären Liste *classes* ein Mapping von Ausgabeindex auf Polygon-ID erstellt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(X_context, X_text, tau_opt):\n",
    "    \n",
    "    # bekannte Hilfsfunktion\n",
    "    def abstain():\n",
    "        y_abs = []\n",
    "        for row in y_pred:            \n",
    "            y_abs.append(np.argmax(row/tau_opt) if np.max(row/tau_opt) > 1 else -1)\n",
    "        return np.asarray(y_abs)\n",
    "\n",
    "    # Klassifikation auf erster Ebene\n",
    "    \n",
    "    # Modelle laden\n",
    "    stacked_classifier = pickle.load(open(\"model_l1.pcl\", \"rb\"))\n",
    "    ensemble = pickle.load(open(\"ensemble_l1.pcl\", \"rb\"))\n",
    "    \n",
    "    # Vorhersagen tätigen\n",
    "    y_1 = stacked_classifier.predict_proba(X_context)\n",
    "    y_2 = X_text[[\"4_0\", \"4_1\", \"4_2\", \"4_3\"]]\n",
    "    \n",
    "    # Ergebnisse mergen\n",
    "    y_pred = ensemble.predict_proba(np.hstack((y_1, y_2)))\n",
    "    \n",
    "    # Ergebnisse abstainen\n",
    "    y_pred = abstain()\n",
    "    \n",
    "    # Ausgabeliste vorbereiten\n",
    "    results = np.ones(X_context.shape[0])\n",
    "    results *= -1\n",
    "    \n",
    "    # genauere Klassifikation für alle verbleibenden Datenpunkte in vier Folgecluster\n",
    "    for i in range(3):\n",
    "        \n",
    "        # Lade i-te Modelle auf 2. Ebene\n",
    "        stacked_classifier = pickle.load(open(\"model_l2_c{}.pcl\".format(i), \"rb\"))\n",
    "        ensemble = pickle.load(open(\"ensemble_l2_c{}.pcl\".format(i), \"rb\"))\n",
    "        \n",
    "        # filtere auf Datenpunkte, die vom i-ten Modell vorhergesagt werden müssen\n",
    "        relevant_indices = np.where(y_pred == i)[0]\n",
    "        if len(relevant_indices) == 0:\n",
    "            continue\n",
    "        X_context_ = X_context.iloc[relevant_indices, :]\n",
    "        classes = ensemble.classes_.tolist()\n",
    "\n",
    "        # Vorhersagen tätigen\n",
    "        y_1 = stacked_classifier.predict_proba(X_context_)\n",
    "        y_2 = X_text.iloc[relevant_indices, :]        \n",
    "        #y_2 = y_2[\"150\"]\n",
    "        y_2 = y_2[[x for x in stacked_classifier.classes_]]\n",
    "        \n",
    "        y_pred_ = ensemble.predict_proba(np.hstack((y_1, y_2)))\n",
    "        \n",
    "        for i, v in zip(relevant_indices, y_pred_):\n",
    "            v = np.argmax(v)\n",
    "            results[i] = classes[v]\n",
    "    \n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Anwendung obiger Funktion ist sehr simpel, siehe nachfolgende Zelle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 94.,  40., 106., ...,  49., 132., 116.])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = classify_data(df_feat, df_text, dist*alpha_opt)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
